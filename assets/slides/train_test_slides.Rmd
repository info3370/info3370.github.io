---
output: beamer_presentation
header-includes:
  \usepackage{tikz}
  \usetikzlibrary{arrows,shapes.arrows,positioning,shapes,patterns,calc}
  \newcommand\bblue[1]{\textcolor{blue}{\textbf{#1}}}
---

#

\begin{tikzpicture}[x = \textwidth, y = \textheight]
\node at (0,0) {};
\node at (1,1) {};
\node[anchor = north west, align = left, font = \huge] at (0,.9) {Studying\\Social Inequality\\with Data Science};
\node[anchor = north east, align = right] (number) at (1,.9) {INFO 3370 / 5371\\Spring 2023};
\node[anchor = north, font = \Large, align = right] at (.5,.5) {\bblue{Sample splitting}};
\end{tikzpicture}

# The model selection problem

```{r, echo = F, message = F, comment = F}
library(tidyverse)
library(rsample)
set.seed(14850)
```

In supervised machine learning, the goal is to

- learn patterns in the available data
- predict outcomes for previously unseen cases \vskip .1in

```{r, echo = F, fig.height = 2.5, dpi = 300}
p <- ggplot() +
  theme_void() +
  # Fix the canvas
  annotate(geom = "point", x = 1.25, y = 4.2, color = "white") +
  annotate(geom = "point", x = 5, y = 2, color = "white") +
  # Predictor box
  annotate(geom = "text", x = 1, y = 4, vjust = -1, label = "Predictor Variables", fontface = "bold") +
  annotate(geom = "text", x = 0, y = 2, vjust = -1, label = "Cases", fontface = "bold", angle = 90) +
  annotate(geom = "rect", xmin = 0, xmax = 2, ymin = 0, ymax = 4, fill = "white", color = "black") +
  # Learning set box  
  annotate(geom = "rect", xmin = 3, xmax = 4, ymin = 2, ymax = 4, fill = "white", color = "black") +
  annotate(geom = "text", x = 3.5, y = 4, vjust = -1, label = "Outcomes", fontface = "bold") +
  annotate(geom = "text", x = 3.5, y = 3, label = "Learning\nSet") +
  # Holdout set box
  annotate(geom = "rect", xmin = 3, xmax = 4, ymin = 0, ymax = 2, fill = "darkgray", color = "black") +
  annotate(geom = "text", x = 3.5, y = 1, label = "Holdout\nSet", color = "white") +
  # What is available to data analyst
  annotate(geom = "text", x = 4.25, y = 3, hjust = 0, label = "Available\nto Data Analyst", size = 3.2) +
  annotate(geom = "text", x = 4.25, y = 1, hjust = 0, label = "Never Available\nto Data Analyst", size = 3.2) +
  annotate(geom = "segment", linewidth = .3,
           arrow = arrow(length = unit(.05,"in")),
           x = 4.2, xend = 4.1, 
           y = c(.7,1.3,2.7,3.3),
           yend = c(.55,1.45,2.55,3.45)) +
  # Learning
  annotate(geom = "segment", x = 2.2, xend = 2.8, y = 3, yend = 3, arrow = arrow(length = unit(.05,"in"))) +
  annotate(geom = "text", fontface = "bold", x = 2.5, y = 3.1, vjust = 0, label = "Learn") +
  annotate(geom = "text", x = 2.5, y = 2.9, vjust = 1, label = "Discover\nPatterns", size = 3.2) +
  # Task
  annotate(geom = "segment", x = 2.2, xend = 2.8, y = 1, yend = 1, arrow = arrow(length = unit(.05,"in"))) +
  annotate(geom = "text", fontface = "bold", x = 2.5, y = 1.1, vjust = 0, label = "Task") +
  annotate(geom = "text", x = 2.5, y = .9, vjust = 1, label = "Predict for\nNew Cases", size = 3.2)
print(p)
```

\vskip .2in \pause
How do we know which method will do this well?

# Key principle

When a task involves unseen data,

- try to mimic that task with data you already have
- pick the method that performs best on your mimic task

# Goal: Predict the unseen outcomes in a holdout set

```{r, echo = F, fig.height = 2.5, dpi = 300}
print(p)
```

# Mimic the task: Sample split

```{r, echo = F, fig.height = 2.5, dpi = 300}
p2 <- p +
  # Block things to write over
  annotate(geom = "rect", xmin = 2.1, xmax = 2.9, ymin = 2, ymax = 4, fill = "white", color = "white") +
  annotate(geom = "rect", xmin = 3.1, xmax = 3.9, ymin = 2.1, ymax = 3.9, fill = "white", color = "white") +
  # Train set
  annotate(geom = "rect", xmin = 3, xmax = 4, ymin = 3, ymax = 4, fill = "seagreen4", alpha = .8) +
  annotate(geom = "text", x = 3.5, y = 3.5, color = "white", label = "Train Set") +
  # Test set
  annotate(geom = "rect", xmin = 3, xmax = 4, ymin = 2, ymax = 3, fill = "blue", alpha = .8) +
  annotate(geom = "text", x = 3.5, y = 2.5, color = "white", label = "Test Set") +
  # Estimation
  annotate(geom = "segment", x = 2.2, xend = 2.8, y = 3.5, yend = 3.5, arrow = arrow(length = unit(.05,"in"))) +
  annotate(geom = "text", fontface = "bold", x = 2.5, y = 3.6, vjust = 0, label = "Estimate") +
  annotate(geom = "text", x = 2.5, y = 3.4, vjust = 1, label = "Discover Patterns", size = 3.2) +
  # Evaluation
  annotate(geom = "segment", x = 2.2, xend = 2.8, y = 2.5, yend = 2.5, arrow = arrow(length = unit(.05,"in"))) +
  annotate(geom = "text", fontface = "bold", x = 2.5, y = 2.6, vjust = 0, label = "Evaluate") +
  annotate(geom = "text", x = 2.5, y = 2.4, vjust = 1, label = "Select Model", size = 3.2)
print(p2)
```

# Sample split in R

1. Load the data
2. Create a train-test split
3. Learn candidate prediction functions in the train set
4. Evaluate predictive performance in the test set
5. Estimate the chosen model in the full learning set and predict in the holdout set

# Prepare environment

You'll want

- the `tidyverse` package
- the `rsample` package, which we will use to make the split
- use `set.seed()` with a number of your choosing to ensure reproducibility despite random sampling

```{r, eval = F}
library(tidyverse)
library(rsample)
set.seed(14850)
```

# 1. Load the data

```{r, message = F, warning = F}
learning <- read_csv("learning.csv")
holdout_public <- read_csv("holdout_public.csv")
```

# 2. Create a train-test split
\pause

In the `rsample` package,

- the `initial_split()` function will create a split
```{r}
learning_split <- learning %>%
  initial_split(prop = 0.5)
```  
\pause
- the `training()` and `testing()` functions will create data frames
```{r}
train <- training(learning_split)
test <- testing(learning_split)
```

# 3. Learn candidate prediction functions on the train set

We will illustrate with OLS. \pause We will consider

1. parent income
2. parent income + race + sex
3. parent income $\times$ race $\times$ sex
\pause
```{r}
candidate_1 <- lm(g3_log_income ~ g2_log_income,
                  data = train)
candidate_2 <- lm(g3_log_income ~ g2_log_income + 
                    race + sex,
                  data = train)
candidate_3 <- lm(g3_log_income ~ g2_log_income * 
                    race * sex,
                  data = train)
```

# 3. Learn candidate prediction functions on the train set

```{r, echo = F}
train %>%
  mutate(candidate_1 = predict(candidate_1),
         candidate_2 = predict(candidate_2),
         candidate_3 = predict(candidate_3)) %>%
  pivot_longer(cols = starts_with("candidate"),
               names_to = "model", 
               values_to = "yhat") %>%
  mutate(model = case_when(model == "candidate_1" ~ "Income",
                           model == "candidate_2" ~ "Income + Race + Sex",
                           model == "candidate_3" ~ "Income x Race x Sex")) %>%
  rename(Sex = sex, Race = race) %>%
  ggplot(aes(x = g2_log_income, color = Race, linetype = Sex, y = yhat)) +
  geom_line() +
  facet_wrap(~model, ncol = 3) +
  xlab("Parent Log Income") +
  ylab("Predicted Respondent Log Income") +
  theme_bw() +
  theme(text = element_text(size = 20))
```

# 4. Evaluate predictive performance on the test set

```{r}
fitted <- test %>%
  mutate(candidate_1 = predict(candidate_1, 
                               newdata = test),
         candidate_2 = predict(candidate_2, 
                               newdata = test),
         candidate_3 = predict(candidate_3, 
                               newdata = test)) %>%
  pivot_longer(cols = starts_with("candidate"),
               names_to = "model", 
               values_to = "yhat")
```

# 4. Evaluate predictive performance on the test set

```{r}
fitted %>%
  group_by(model) %>%
  mutate(error = g3_log_income - yhat) %>%
  mutate(squared_error = error ^ 2) %>%
  summarize(mse = mean(squared_error))
```
\pause \vskip .1in

Candidate 2 wins!

# Side note: Train versus test set error
\pause

```{r, echo = F}
train %>%
  # Make predictions from the models
  mutate(candidate_1 = predict(candidate_1),
         candidate_2 = predict(candidate_2),
         candidate_3 = predict(candidate_3)) %>%
  # Pivot longer so we can summarize them all in one line
  pivot_longer(cols = starts_with("candidate"),
               names_to = "model", values_to = "yhat") %>%
  group_by(model) %>%
  mutate(error = g3_log_income - yhat) %>%
  mutate(squared_error = error ^ 2) %>%
  summarize(train_set_mse = mean(squared_error)) %>%
  left_join(
    fitted %>%
  group_by(model) %>%
  # Calculate prediction error
  mutate(error = g3_log_income - yhat) %>%
  # Calculate squared prediction error
  mutate(squared_error = error ^ 2) %>%
  # Calculate mean squared error
  summarize(test_set_mse = mean(squared_error)),
  by = "model"
  ) %>%
  mutate(model = case_when(model == "candidate_1" ~ "Income",
                           model == "candidate_2" ~ "Income + Race + Sex",
                           model == "candidate_3" ~ "Income x Race x Sex"))
```
\vskip .2in \pause
What happened? \pause Overfitting. \pause

- candidate 3 is very flexible \pause
- discovers patterns that do not generalize \pause
- performs poorly in test (and holdout)

# 5. Estimate in all of learning. Predict in the holdout set

With our chosen model, now estimate with all the data we have

```{r}
chosen <- lm(g3_log_income ~ g2_log_income + 
               race + sex,
             data = learning)
```
\pause
Predict for the holdout set

```{r}
predicted <- holdout_public %>%
  mutate(predicted = predict(chosen, 
                             newdata = holdout_public))
```

# Summary: Mimic the task with data you have


```{r, fig.height = 2.5, echo = F}
print(p)
```
\vskip .2in
```{r, fig.height = 2.5, echo = F}
print(p2)
```

